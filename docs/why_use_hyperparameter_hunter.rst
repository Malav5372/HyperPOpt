Why Use HyperparameterHunter?
*****************************
This section provides an overview of the mission and primary uses of HyperparameterHunter, as well as some of its main features.

TL;DR
=====
* HyperparameterHunter saves your Experiments to provide:

    1) Enhanced, long-term hyperparameter optimization; and
    2) Improved awareness of what you've done, what works, and what you should try next

What is HyperparameterHunter?
=============================
* Don't think of HyperparameterHunter as a new machine learning tool; its a toolbox

    * There are tons of excellent machine learning libraries. The problem is keeping track of them all
    * Impractical to keep track of which libraries work, which hyperparameters are best for whichever algorithms, and how your
      experiment was set up
    * Let HyperparameterHunter organize your tools for you, while you focus on using the best tool for the job
    * Stop wasting time debating between a screwdriver and a wrench, when you're staring at a nail

* Not a new thing to try alongside other algorithms. Its a new way of doing the things you already do

    * Keep using the libraries/algorithms you know and love, just tell HyperparameterHunter about them

* Provides a simple wrapper for executing machine learning algorithms

    * Automatically saves the testing conditions/hyperparameters, results, predictions, and more
    * Test and evaluate wide range of algorithms from many different libraries in a unified format

Features
========
* Stop worrying about keeping track of hyperparameters, scores, or re-running the same Experiments
* See records of all your Experiments: from birds-eye-view leaderboards, to individual result files
* Supercharge informed hyperparameter optimization by allowing it to use saved Experiments

    * No need to hold HyperparameterHunter's hand while it tries to find the Experiment you ran months ago
    * It automatically reads your Experiment files to find the ones that fit, and it learns from them

* Eliminate boilerplate code for cross-validation loops, predicting, and scoring
* Have predictions ready to go when its time for ensembling, meta-learning, and finalizing your models
